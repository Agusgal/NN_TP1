{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 1\n",
    "Se buscó analizar si existe un sesgo en el dataset de snli donde el contenido mismo del texto puede estar delatando si existe una contradicción con respecto a la hipótesis oculta.\n",
    "## Carga de Datos\n",
    "Se cargaron los datasets correspondientes para observación, ya divididos en datos de entrenamiento, validación y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cargo los datos\n",
    "df_train = pd.read_hdf(\"./train_data.hdf5\")\n",
    "df_valid = pd.read_hdf(\"./valid_data.hdf5\")\n",
    "df_test = pd.read_hdf(\"./test_data.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_submission = pd.read_csv(\"/kaggle/input/sesgos-en-el-dataset-de-snli/submission_sample.csv\", index_col=\"pairID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_train = df_train[\"text\"].tolist()\n",
    "labels_train = df_train[\"gold_label\"].tolist()\n",
    "text_val = df_valid[\"text\"].tolist()\n",
    "labels_val = df_valid[\"gold_label\"].tolist()\n",
    "text_test = df_test[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'contradiction': 183187, 'entailment': 183416, 'neutral': 182764})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Veamos el balance de clases\n",
    "from collections import Counter\n",
    "Counter(labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-procesamiento de Texto\n",
    "+ NLTK (Natural Language Toolkit)\n",
    "  + Lemmatization: reduce a sus significados (ej, quita conjugación verbal)\n",
    "  + Stop Words: quita preposiciones (como palabras muy usuales de relleno?)\n",
    "  + Stemming: reduce las palabras a su raíz\n",
    "  + Filtrado de no palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ohvic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ohvic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ohvic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# Paquetes de Natural Language Tool Kit\n",
    "import nltk\n",
    "#Tokenización (a partir de este se trabajan las otras combinacionies)\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Función con la cual también decido cómo pre-procesar\n",
    "def text_filter(dataset, do_lemm, do_stop, do_stem, do_alpha):\n",
    "    texts_filtrados = list()\n",
    "    for idx in range(len(dataset.text)):\n",
    "        if idx%100==0:\n",
    "            print(\"\\r Procesados: {}\".format(idx),end=\"\")\n",
    "        em = dataset.text[idx]\n",
    "        tok = word_tokenize(em)\n",
    "        if do_lemm == True:\n",
    "            lem = [lemmatizer.lemmatize(x,pos='v') for x in tok]\n",
    "        else:\n",
    "            lem = tok\n",
    "        if do_stop == True:\n",
    "            stop = [x for x in lem if x not in stopwords.words('english')]\n",
    "        else:\n",
    "            stop = lem\n",
    "        if do_stem == True:\n",
    "            stem = [stemmer.stem(x) for x in stop]\n",
    "        else:\n",
    "            stem = stop\n",
    "        if do_alpha == True:\n",
    "            alpha = [x for x in stem if x.isalpha()]\n",
    "        else:\n",
    "            alpha = stem\n",
    "        texts_filtrados.append(\" \".join(alpha))\n",
    "    return texts_filtrados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizadores\n",
    "+ Count Vectorizer\n",
    "+ TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Importo los vectorizadores\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_max = 1.0 # max_df: int para frecuencia contada, float para proporcional\n",
    "df_min = 10 # min_df: idem\n",
    "n_range = (1,1) # ngram_range: (1,1) default\n",
    "cv_cv = CountVectorizer(max_df = df_max, min_df= df_min, ngram_range = n_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_max = 1.0\n",
    "df_min = 10\n",
    "n_range = (1,1)\n",
    "cv_idf = TfidfVectorizer(max_df = df_max, min_df= df_min, ngram_range = n_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cvs(text_train, text_valid, cv):\n",
    "    cv_train = cv.fit_transform(text_train)\n",
    "    cv_valid = cv.transform(text_valid)\n",
    "    return cv_train, cv_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calisificadores\n",
    "+ Multinomial Naive-Bayes\n",
    "+ Regresión Logística (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parámetros del Clasificador\n",
    "a = 1e-10\n",
    "clf_NBMN = MultinomialNB(alpha = a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilevel Perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden_units, input_shape=(input_dim,), activation='relu'))\n",
    "model.add(Dense(10, activation='tanh'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "# Dimm capa entrada: num de vocablos\n",
    "# Dimm capa salida: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas\n",
    "Las metricas de evaluacion que se utilizan para evaluar un metodo de clasificacion y ademas comparar varios metodos de clasificacion aplicados a un mismo conjunto de datos. Tambien se puede evaluar el comportamiento dado por un cambio de parametros en un metodo. \n",
    "La evaluacion del modelo se hace a partir de los datos que se encuentran en test, siendo clasidicacion supervisada. \n",
    "Hay que considerar los distintos tipos de datos para las metricas de evaluacion: \n",
    "\n",
    "\t* Verdaderos positivos: El valor real es positivo y  la prueba predijo tambien que era positivo.\n",
    "\t* Verdaderos Negativos: El valor real  es negativo y la prueba predijo tambien que el resultado era negativo.\n",
    "\t* Falsos positivos: El valor real es negativo, y la prueba predijo  que el resultado es positivo. \n",
    "\t* Falsos negativos: El valor real es positivo, y la prueba predijo  que el resultado es negativo. \n",
    "\n",
    "Se utilizaron metricas para la evaluacion del rendimiento, siendo estas:\n",
    "\t* precision\n",
    "\t* recall_score\n",
    "\t* f1_score\n",
    "\t* ROC AUG\n",
    "Ninguno de estos criterios por separado da una buena evaluacion de un metodo de clasificacion y hay que utilizar varios criterios al mismo tiempo.\n",
    "\n",
    "La curva ROC es el grafico de la tasa de verdaderos positivos contra la tasa de falsos positivos. Luego es posible analizar el error en la clasificacion midiendo el area debajo de la curva. Cuanto mas cerca de 1 este el area, mejor sera la clasificacion. El area debajo de la curva ROC o AUG es una metrica que puede ser\n",
    "utilizada para comparar diferentes test de clasificacion. Es una medida de la precision del test. Se calcula con un metodo de integracion numerica.\n",
    "\n",
    "Se calcularon todas pero a la hora de pensar en la robustez de un metodo hay que tener en cuenta las ventajas y las desventajas que tiene cada uno de las metricas. \n",
    "Con la métrica de precisión podemos medir la calidad del modelo de machine learning en tareas de clasificación. Se refiere a la dispersión del conjunto de valores obtenidos a partir de mediciones repetidas de una magnitud. Cuanto menor es la dispersión mayor la precisión. Se representa por la proporción de verdaderos positivos dividido entre todos los resultados positivos (tanto verdaderos positivos, como falsos positivos).\n",
    "\n",
    "$$precision = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "La métrica de exhaustividad nos va a informar sobre la cantidad que el modelo de machine learning es capaz de identificar. Es tambien llamada tasa de verdaderos positivos es la probabilidad de que un resultado positivo real dé positivo.\n",
    "\n",
    "$$recall = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "El valor F1 se utiliza para combinar las medidas de precision y recall en un sólo valor. Esto es práctico porque hace más fácil el poder comparar el rendimiento combinado de la precisión y la exhaustividad entre varias soluciones. Es de gran utilidad cuando la distribución de las clases es desigual.\n",
    "$$F1 = 2 \\cdot \\frac{precision \\cdot recall}{precision + recall} $$\n",
    "\n",
    "Hay otra metrica llamada *accuracy* que mide el porcentaje de casos que el modelo ha acertado. Esta no funciona bien cuando las clases están desbalanceadas. En este caso se pudo ver que las clases estaban bien balanceadas por lo que se opto la misma como metrica primaria. Si no hubiese sido asi, es decir las clases desbalanceadas, es mucho mejor usar precision, recall y F1. Estas métricas dan una mejor idea de la calidad del modelo.\n",
    "$$accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "\n",
    "El sesgo es la diferencia entre el valor medio y el verdadero valor de la magnitud medida. El sesgo pertenece al concepto de exactitud.\n",
    "\n",
    "Conforme a las metricas mencionadas podemos obtener cuatro casos posibles para cada clase:\n",
    "\n",
    "* **Alta precisión y alto recall:** el modelo de Machine Learning escogido maneja perfectamente esa clase.\n",
    "* **Alta precisión y bajo recall:** el modelo de Machine Learning escogido no detecta la clase muy bien, pero cuando lo hace es altamente confiable.\n",
    "* **Baja precisión y alto recall:** El modelo de Machine Learning escogido detecta bien la clase,  pero también incluye muestras de la otra clase.\n",
    "* **Baja precisión y bajo recall:** El modelo de Machine Learning escogido no logra clasificar la clase correctamente.\n",
    "\n",
    "Para un *dataset* desequilibrado se puede caer en la obtencion de un alto valor de precisión en la clase Mayoritaria y un bajo recall en la clase Minoritaria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_scores(clf, X_train, y_train, X_valid, y_valid):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_valid)\n",
    "    \n",
    "    score_train = clf.score(X_train, y_train)\n",
    "    score_valid = clf.score(X_valid, y_valid)\n",
    "    return (score_train, score_valid)\n",
    "    \n",
    "def get_metrics(clf, X_valid, y_valid):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    m_conf = metrics.confusion_matrix(y_valid, y_pred)\n",
    "    precision = metrics.precision_score(y_valid, y_pred)\n",
    "    recall_score = metrics.recall_score(y_valid,y_pred)\n",
    "    f1_score = metrics.f1_score(y_valid,y_pred)\n",
    "    acc = metrics.accuracy_score(y_valid, y_pred)\n",
    "    \n",
    "    return score_train, score_valid, m_conf, precision, recall_score, f1_score, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Función que hace todo lo anterior de una\n",
    "def process_data(clf, cv, df_train, df_valid, do_lemm, do_stop, do_stem, do_alpha):\n",
    "    print(\"\\n  Filtrando Textos\")\n",
    "    texts_train = text_filter(df_train, do_lemm, do_stop, do_stem, do_alpha)\n",
    "    texts_valid = text_filter(df_valid, do_lemm, do_stop, do_stem, do_alpha)\n",
    "    \n",
    "    labels_train = df_train[\"gold_label\"].tolist()\n",
    "    labels_valid = df_valid[\"gold_label\"].tolist()\n",
    "    \n",
    "    print(\"\\nVectorizando\")\n",
    "    cv_train, cv_valid = get_cvs(texts_train, texts_valid, cv)\n",
    "    \n",
    "    print(\"Obteniendo Puntajes\")\n",
    "    score_train, score_valid = get_scores(clf, cv_train, labels_train, cv_valid, labels_valid)\n",
    "    return (cv_train, cv_valid, score_train, score_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Filtrando Textos\n",
      " Procesados: 980000\n",
      "Vectorizando\n",
      "Obteniendo Puntajes\n",
      "\n",
      "  Filtrando Textos\n",
      " Procesados: 980000\n",
      "Vectorizando\n",
      "Obteniendo Puntajes\n",
      "\n",
      "  Filtrando Textos\n",
      " Procesados: 980000\n",
      "Vectorizando\n",
      "Obteniendo Puntajes\n",
      "\n",
      "  Filtrando Textos\n",
      " Procesados: 980000\n",
      "Vectorizando\n",
      "Obteniendo Puntajes\n",
      "\n",
      "  Filtrando Textos\n",
      " Procesados: 980000\n",
      "Vectorizando\n",
      "Obteniendo Puntajes\n"
     ]
    }
   ],
   "source": [
    "test_raw = process_data(clf_NBMN, cv_cv, df_train, df_valid, False, False, False, False)\n",
    "test_lemm = process_data(clf_NBMN, cv_cv, df_train, df_valid, True, False, False, False)\n",
    "test_stop = process_data(clf_NBMN, cv_cv, df_train, df_valid, False, True, False, False)\n",
    "test_stem = process_data(clf_NBMN, cv_cv, df_train, df_valid, False, False, True, False)\n",
    "test_alfa = process_data(clf_NBMN, cv_cv, df_train, df_valid, False, False, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Valid:\n",
      "raw:   0.6220704920390194 ;  0.6228408859987807\n",
      "lemm:  0.6174324267748154 ;  0.6197927250558829\n",
      "stop:  0.6136462510489346 ;  0.6184718553139605\n",
      "stem:  0.6168572193087681 ;  0.6187766714082503\n",
      "alfa:  0.6215644550910412 ;  0.6224344645397277\n"
     ]
    }
   ],
   "source": [
    "print(\"Train/Valid:\")\n",
    "print(\"raw:  \",  test_raw[2],\"; \",  test_raw[3])\n",
    "print(\"lemm: \", test_lemm[2],\"; \", test_lemm[3])\n",
    "print(\"stop: \", test_stop[2],\"; \", test_stop[3])\n",
    "print(\"stem: \", test_stem[2],\"; \", test_stem[3])\n",
    "print(\"alfa: \", test_alfa[2],\"; \", test_alfa[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando los resultados de estas pruebas, parece ser que aplicar cualquiera de los filtros de lenguaje natural resulta en una disminusión en la capacidad del modelo de predecir correctamente los resultados deseados. Esto puede deberse a que existe información dentro de cada elemento eliminado que podría llevar a concluir si la frase es contradictoria, neutral o afirmativa.\n",
    "\n",
    "Debido a esto, se procederá a trabajar con los datos sin aplicar los filtros del paquete NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finalmente se trabaja sin filtros\n",
    "text_train_final = text_train\n",
    "text_valid_final = text_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definido el pre-procesamiento se analizó si se obtienen mejores resultados utilizando el CountVectorizer o TFIDFVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_max = 1.0 # max_df: int para frecuencia contada, float para proporcional\n",
    "df_min = 10 # min_df: idem\n",
    "n_range = (1,2) # ngram_range: (1,1) default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv_cv = CountVectorizer(max_df = df_max, min_df= df_min, ngram_range = n_range)\n",
    "cv_idf = TfidfVectorizer(max_df = df_max, min_df= df_min, ngram_range = n_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6493109342206576, 0.638996138996139)\n",
      "(0.6588510048838027, 0.6470229628124365)\n"
     ]
    }
   ],
   "source": [
    "cv_train, cv_valid = get_cvs(text_train_final, text_valid_final, cv_cv)\n",
    "cv_scores = get_scores(clf_NBMN, cv_train, labels_train, cv_valid, labels_val)\n",
    "cv_train, cv_valid = get_cvs(text_train_final, text_valid_final, cv_idf)\n",
    "idf_scores = get_scores(clf_NBMN, cv_train, labels_train, cv_valid, labels_val)\n",
    "\n",
    "print(cv_scores)\n",
    "print(idf_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bajo las mismas condiciones el TFIDF Vectorizer parece tener un mejor rendimiento a la hora de predecir los resultados correctamente. Por lo tanto las siguientes pruebas se harán con el TFIDF.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hago un Sweep para optimizar el min_df\n",
    "train_scores = list()\n",
    "valid_scores = list()\n",
    "df_mins = range(5,15,1)\n",
    "for i in df_mins:\n",
    "    cv = TfidfVectorizer(max_df = df_max, min_df= i, ngram_range = n_range)\n",
    "    cv_train, cv_valid = get_cvs(text_train_final, text_valid_final, cv)\n",
    "    scores = get_scores(clf_NBMN, cv_train, labels_train, cv_valid, labels_val)\n",
    "    train_scores.append(scores[0])\n",
    "    valid_scores.append(scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x176c7b81100>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(df_mins,train_scores)\n",
    "plt.plot(df_mins,valid_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con un min_df = 8 se obtuvo el score_valid más alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puedo hacer el sweep para ver qué onda si cambio max_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algo pasa más arriba de acá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15592/3388480427.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlabels_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "clf.fit(cv_train, labels_train)\n",
    "labels_pred = clf.predict(cv_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veamos cómo funciona el clasificador para train\n",
    "clf.score(cv_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos cómo funciona el clasificador para valid\n",
    "clf.score(cv_valid, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_test = cv.transform(text_test_final)\n",
    "get_metrics(clf, cv_test, labels_test)\n",
    "# test_labels = clf.predict(cv_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-30T23:10:56.758334Z",
     "iopub.status.busy": "2021-09-30T23:10:56.758071Z",
     "iopub.status.idle": "2021-09-30T23:11:11.004797Z",
     "shell.execute_reply": "2021-09-30T23:11:11.004015Z",
     "shell.execute_reply.started": "2021-09-30T23:10:56.758307Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parámetros de Pre-procesamiento (sin procesamiento)\n",
    "text_train_final = text_train\n",
    "text_valid_final = text_val\n",
    "\n",
    "# Parámetros del Count Vectorizer\n",
    "df_max = 1.0 # max_df: int para frecuencia contada, float para proporcional\n",
    "df_min = 8 # min_df: obtenido de una curva\n",
    "n_range = (1,2) # ngram_range: (1,1) default\n",
    "\n",
    "cv = TfidfVectorizer(max_df = df_max, min_df= df_min, ngram_range = n_range)\n",
    "\n",
    "# Parámetros del Clasificador\n",
    "a = 1e-4\n",
    "clf = MultinomialNB(alpha = a)\n",
    "\n",
    "cv_train = cv.fit_transform(text_train_final)\n",
    "cv_val = cv.transform(text_valid_final)\n",
    "clf.fit(cv_train, labels_train)\n",
    "\n",
    "cv_test = cv.transform(text_test)\n",
    "test_labels = clf.predict(cv_test)\n",
    "\n",
    "get_metrics(clf, cv_val, labels_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas del modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Para armar Submission\n",
    "Una vez elegido el grado de pre-procesamiento, el vectorizador y el clasificador, lo aplico sobre el el test.\n",
    "+ Preprocesamiento: Lemmatization, Stemming y No-Palabras\n",
    "+ Vectorizador: TFIDF\n",
    "+ Clasificador: Multinomial Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-30T23:11:16.015681Z",
     "iopub.status.busy": "2021-09-30T23:11:16.015374Z",
     "iopub.status.idle": "2021-09-30T23:11:16.022765Z",
     "shell.execute_reply": "2021-09-30T23:11:16.021643Z",
     "shell.execute_reply.started": "2021-09-30T23:11:16.015647Z"
    }
   },
   "outputs": [],
   "source": [
    "#Armo el submission.csv\n",
    "df_test = pd.DataFrame(data=test_labels, columns=[\"pred_labels\"],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-30T23:11:19.912203Z",
     "iopub.status.busy": "2021-09-30T23:11:19.911878Z",
     "iopub.status.idle": "2021-09-30T23:11:19.927182Z",
     "shell.execute_reply": "2021-09-30T23:11:19.926050Z",
     "shell.execute_reply.started": "2021-09-30T23:11:19.912173Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-30T23:11:30.239971Z",
     "iopub.status.busy": "2021-09-30T23:11:30.239675Z",
     "iopub.status.idle": "2021-09-30T23:11:30.244073Z",
     "shell.execute_reply": "2021-09-30T23:11:30.243080Z",
     "shell.execute_reply.started": "2021-09-30T23:11:30.239919Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test.index.names = [\"pairID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-30T23:11:32.944424Z",
     "iopub.status.busy": "2021-09-30T23:11:32.943772Z",
     "iopub.status.idle": "2021-09-30T23:11:32.957075Z",
     "shell.execute_reply": "2021-09-30T23:11:32.956462Z",
     "shell.execute_reply.started": "2021-09-30T23:11:32.944384Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-30T23:11:39.729730Z",
     "iopub.status.busy": "2021-09-30T23:11:39.728868Z",
     "iopub.status.idle": "2021-09-30T23:11:39.764287Z",
     "shell.execute_reply": "2021-09-30T23:11:39.763581Z",
     "shell.execute_reply.started": "2021-09-30T23:11:39.729688Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones\n",
    "A partir de las métricas obtenidas por el momento se puede decir que existe un sesgo en la selección de textos para la validación de premisas en el *dataset* de SNLI, dado que es posible obtener resultados correctos en el 65% de los casos, incluso con una baja cantidad de optimizaciones, a partir de solo las hipótesis y desconocer las premisas correspondientes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rn_tp1]",
   "language": "python",
   "name": "conda-env-rn_tp1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
